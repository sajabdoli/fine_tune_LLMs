# fine_tune_LLMs
This repo contains a notebook for fine tuning the LLM based on the DPO (Direct Preference Optimization) method. For reducing the trainable parameters we also incorporate LoRA (Low-Rank Adaptation of Large Language Models)

For a microsoft/phi-2 model there are: trainable params: 4,792,320 || all params: 2,784,476,160 || trainable%: 0.1721
